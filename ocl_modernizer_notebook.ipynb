{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCL Reference Modernizer\n",
    "\n",
    "**GitHub Issue**: [#2212](https://github.com/OpenConceptLab/ocl_issues/issues/2212)\n",
    "\n",
    "## Overview\n",
    "This notebook modernizes OCL (Open Concept Lab) collection references by:\n",
    "1. ðŸ“¥ Loading references from OCL collection version export JSON\n",
    "2. ðŸ” Identifying versioned references using URL pattern matching\n",
    "3. âœ¨ Generating unversioned equivalents ONLY for versioned references\n",
    "4. ðŸ“¤ Creating bulk import/delete files in JSONL format for OCL API\n",
    "5. ðŸ”§ Supporting multiple cascade presets (OpenMRS, Custom, etc.)\n",
    "6. ðŸš« Preventing duplicate expressions\n",
    "7. ðŸ“Š Reporting detailed statistics on the transformation\n",
    "\n",
    "## Acceptance Criteria âœ…\n",
    "- âœ… Parse references from OCL collection version export JSON\n",
    "- âœ… Identify versioned references using URL pattern matching\n",
    "- âœ… Generate unversioned equivalents ONLY for versioned references\n",
    "- âœ… Create bulk import/delete JSONL files\n",
    "- âœ… Handle cascade configuration with presets\n",
    "- âœ… Prevent duplicate expressions\n",
    "- âœ… Report concept/mapping reference counts\n",
    "\n",
    "## Instructions\n",
    "1. **Run cells sequentially** from top to bottom\n",
    "2. **Configure your settings** in the Configuration cell\n",
    "3. **Set your input file path** to your OCL export JSON\n",
    "4. **Choose cascade preset** (OpenMRS, Custom, etc.)\n",
    "5. **Review outputs** before applying to your collection\n",
    "6. **Use OCL's Bulk Import Interface** to apply the generated files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages imported successfully!\n",
      "ðŸ• Notebook started at: 2025-08-20 10:56:15\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional, Set\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")\n",
    "print(f\"ðŸ• Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration\n",
    "\n",
    "**ðŸ”§ Configure your settings here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Configuration loaded:\n",
      "   ðŸ“ Input file: input-example-jamlung/export.json\n",
      "   ðŸ“‚ Output directory: output\n",
      "   ðŸ• Timestamp: 20250820_105615\n",
      "   ðŸ”§ Preserve cascade: True\n",
      "   ðŸŽ›ï¸ Cascade preset: OPENMRS_WITHOUT_TRANSFORM\n",
      "   ðŸš« Skip duplicates: True\n",
      "\n",
      "âš ï¸ Make sure to update INPUT_FILE with your actual export file path!\n",
      "âš ï¸ Choose your CASCADE_PRESET based on your needs!\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - CUSTOMIZE THESE SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "class CascadePresets:\n",
    "    \"\"\"Predefined cascade configurations for different use cases.\"\"\"\n",
    "    \n",
    "    # OpenMRS cascade with transform\n",
    "    OPENMRS_WITH_TRANSFORM = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET\",\n",
    "        \"cascade_levels\": \"*\",\n",
    "        \"return_map_types\": \"*\",\n",
    "        \"transform\": \"openmrs\"\n",
    "    }\n",
    "    \n",
    "    # OpenMRS cascade without transform\n",
    "    OPENMRS_WITHOUT_TRANSFORM = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET\",\n",
    "        \"cascade_levels\": \"*\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "    \n",
    "    # Source to mappings only\n",
    "    SOURCE_TO_MAPPINGS = {\n",
    "        \"method\": \"sourcetomappings\",\n",
    "        \"map_types\": \"*\",\n",
    "        \"cascade_levels\": \"1\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "    \n",
    "    # No cascade (simple references)\n",
    "    NO_CASCADE = None\n",
    "    \n",
    "    # Custom cascade (to be defined by user)\n",
    "    CUSTOM = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET\",\n",
    "        \"cascade_levels\": \"*\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the reference modernizer.\"\"\"\n",
    "    \n",
    "    # ðŸ“ INPUT FILE - SET THIS TO YOUR OCL EXPORT JSON FILE\n",
    "    INPUT_FILE = \"input-example-jamlung/export.json\"  # âš ï¸ CHANGE THIS TO YOUR FILE PATH\n",
    "    \n",
    "    # ðŸ“‚ Output Settings\n",
    "    OUTPUT_DIR = \"output\"\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # ðŸ“„ File naming\n",
    "    UNVERSIONED_FILE = f\"unversioned_references_{TIMESTAMP}.json\"\n",
    "    DELETE_FILE = f\"references_to_delete_{TIMESTAMP}.json\"\n",
    "    REPORT_FILE = f\"migration_report_{TIMESTAMP}.txt\"\n",
    "    \n",
    "    # ðŸ”§ Processing Options\n",
    "    PRESERVE_ORIGINAL_CASCADE = True  # Try to preserve original cascade settings\n",
    "    PRESERVE_REFERENCE_TYPE = True    # Preserve original reference type from export\n",
    "    \n",
    "    # ðŸŽ›ï¸ Cascade Configuration\n",
    "    # Choose from: OPENMRS_WITH_TRANSFORM, OPENMRS_WITHOUT_TRANSFORM, \n",
    "    #              SOURCE_TO_MAPPINGS, NO_CASCADE, CUSTOM\n",
    "    CASCADE_PRESET = \"OPENMRS_WITHOUT_TRANSFORM\"  # ðŸ”„ CHANGE THIS AS NEEDED\n",
    "    \n",
    "    # ðŸŽ¨ Custom cascade settings (only used if CASCADE_PRESET = \"CUSTOM\")\n",
    "    CUSTOM_CASCADE = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET,SAME-AS\",\n",
    "        \"cascade_levels\": \"2\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "    \n",
    "    # ðŸš« Duplicate handling\n",
    "    SKIP_DUPLICATES = True  # Skip references with duplicate expressions\n",
    "    REPORT_DUPLICATES = True  # Report duplicate expressions found\n",
    "\n",
    "    def get_cascade_settings(self) -> Optional[Dict]:\n",
    "        \"\"\"Get the cascade settings based on the selected preset.\"\"\"\n",
    "        if self.CASCADE_PRESET == \"OPENMRS_WITH_TRANSFORM\":\n",
    "            return CascadePresets.OPENMRS_WITH_TRANSFORM\n",
    "        elif self.CASCADE_PRESET == \"OPENMRS_WITHOUT_TRANSFORM\":\n",
    "            return CascadePresets.OPENMRS_WITHOUT_TRANSFORM\n",
    "        elif self.CASCADE_PRESET == \"SOURCE_TO_MAPPINGS\":\n",
    "            return CascadePresets.SOURCE_TO_MAPPINGS\n",
    "        elif self.CASCADE_PRESET == \"NO_CASCADE\":\n",
    "            return CascadePresets.NO_CASCADE\n",
    "        elif self.CASCADE_PRESET == \"CUSTOM\":\n",
    "            return self.CUSTOM_CASCADE\n",
    "        else:\n",
    "            print(f\"âš ï¸ Unknown cascade preset: {self.CASCADE_PRESET}, using OpenMRS default\")\n",
    "            return CascadePresets.OPENMRS_WITHOUT_TRANSFORM\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"âš™ï¸ Configuration loaded:\")\n",
    "print(f\"   ðŸ“ Input file: {config.INPUT_FILE}\")\n",
    "print(f\"   ðŸ“‚ Output directory: {config.OUTPUT_DIR}\")\n",
    "print(f\"   ðŸ• Timestamp: {config.TIMESTAMP}\")\n",
    "print(f\"   ðŸ”§ Preserve cascade: {config.PRESERVE_ORIGINAL_CASCADE}\")\n",
    "print(f\"   ðŸŽ›ï¸ Cascade preset: {config.CASCADE_PRESET}\")\n",
    "print(f\"   ðŸš« Skip duplicates: {config.SKIP_DUPLICATES}\")\n",
    "print()\n",
    "print(\"âš ï¸ Make sure to update INPUT_FILE with your actual export file path!\")\n",
    "print(\"âš ï¸ Choose your CASCADE_PRESET based on your needs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Utility functions defined successfully!\n",
      "\n",
      "ðŸ§ª Function tests:\n",
      "   Versioned URL test: True (should be True)\n",
      "   Unversioned URL test: False (should be False)\n",
      "   Strip version test: /orgs/CIEL/sources/CIEL/concepts/1015/\n",
      "   Reference type test: concepts\n",
      "   Normalize test: /orgs/ciel/sources/ciel/concepts/1015/\n"
     ]
    }
   ],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def is_versioned_url(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if URL contains a version number after concepts, sources, or mappings.\n",
    "    \n",
    "    Examples of versioned URLs:\n",
    "    - /orgs/CIEL/sources/CIEL/concepts/1015/5282451/\n",
    "    - /users/jamlung/sources/openmrs-demo-source/mappings/76/6495007/\n",
    "    \"\"\"\n",
    "    return bool(re.search(r'/(concepts|sources|mappings)/[^/]+/\\d+/?$', url))\n",
    "\n",
    "\n",
    "def strip_version_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove version number from concepts, sources, or mappings URLs.\n",
    "    \"\"\"\n",
    "    return re.sub(r'/(concepts|sources|mappings)/([^/]+)/\\d+/?$', r'/\\1/\\2/', url)\n",
    "\n",
    "\n",
    "def get_reference_type(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if reference is to concepts or mappings.\n",
    "    \"\"\"\n",
    "    if '/concepts/' in url:\n",
    "        return 'concepts'\n",
    "    elif '/mappings/' in url:\n",
    "        return 'mappings'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "def extract_cascade_from_reference(ref_data: Dict) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Extract cascade settings from original reference data.\n",
    "    \"\"\"\n",
    "    # Look for cascade in various possible locations\n",
    "    cascade_fields = ['cascade', '__cascade', 'cascadeOptions']\n",
    "    \n",
    "    for field in cascade_fields:\n",
    "        if field in ref_data and ref_data[field]:\n",
    "            return ref_data[field]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_expression(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize expression for duplicate detection.\n",
    "    Ensures consistent trailing slashes and case.\n",
    "    \"\"\"\n",
    "    if not expression:\n",
    "        return \"\"\n",
    "    \n",
    "    # Ensure trailing slash for consistency\n",
    "    if not expression.endswith('/'):\n",
    "        expression += '/'\n",
    "    \n",
    "    return expression.lower()\n",
    "\n",
    "print(\"ðŸ”§ Utility functions defined successfully!\")\n",
    "\n",
    "# Test the functions with examples\n",
    "test_versioned = \"/orgs/CIEL/sources/CIEL/concepts/1015/5282451/\"\n",
    "test_unversioned = \"/orgs/CIEL/sources/CIEL/concepts/1015/\"\n",
    "\n",
    "print(f\"\\nðŸ§ª Function tests:\")\n",
    "print(f\"   Versioned URL test: {is_versioned_url(test_versioned)} (should be True)\")\n",
    "print(f\"   Unversioned URL test: {is_versioned_url(test_unversioned)} (should be False)\")\n",
    "print(f\"   Strip version test: {strip_version_from_url(test_versioned)}\")\n",
    "print(f\"   Reference type test: {get_reference_type(test_versioned)}\")\n",
    "print(f\"   Normalize test: {normalize_expression(test_unversioned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define File I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ File I/O functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# FILE I/O FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_collection_export(file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load collection data from OCL version export JSON file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Export file not found: {file_path}\")\n",
    "    \n",
    "    print(f\"ðŸ“¥ Loading collection export from: {file_path}\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… Export file loaded successfully\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_references_from_export(export_data: Dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract references from collection export data.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"ðŸ” Extracting references from export data...\")\n",
    "    \n",
    "    references = export_data.get('references', [])\n",
    "    \n",
    "    if not references:\n",
    "        print(\"   âš ï¸ No references found in export data\")\n",
    "        return []\n",
    "    \n",
    "    if not isinstance(references, list):\n",
    "        print(\"   âŒ References field is not a list\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"   âœ… Found {len(references)} references\")\n",
    "    \n",
    "    # Optional: Show a sample reference structure for debugging\n",
    "    if references:\n",
    "        sample_ref = references[0]\n",
    "        print(f\"   ðŸ“‹ Sample reference keys: {list(sample_ref.keys())}\")\n",
    "        if 'expression' in sample_ref:\n",
    "            print(f\"   ðŸ“‹ Sample expression: {sample_ref['expression']}\")\n",
    "    \n",
    "    return references\n",
    "\n",
    "\n",
    "def save_jsonl(data: List[Dict], filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save data as JSONL (JSON Lines) format compatible with OCL bulk import.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for item in data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        print(f\"ðŸ’¾ Saved {len(data)} items to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"âŒ Error saving {filename}: {e}\")\n",
    "\n",
    "print(\"ðŸ“ File I/O functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Reference Processing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Processing classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# REFERENCE PROCESSING CLASSES\n",
    "# =============================================================================\n",
    "\n",
    "class ReferenceProcessor:\n",
    "    \"\"\"Handles the processing and transformation of references.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.stats = {\n",
    "            'total_references': 0,\n",
    "            'versioned_references': 0,\n",
    "            'unversioned_references': 0,\n",
    "            'concept_references': 0,\n",
    "            'mapping_references': 0,\n",
    "            'other_references': 0,\n",
    "            'cascade_preserved': 0,\n",
    "            'cascade_preset': 0,\n",
    "            'duplicates_found': 0,\n",
    "            'duplicates_skipped': 0,\n",
    "            'references_to_modernize': 0,\n",
    "            'references_unchanged': 0\n",
    "        }\n",
    "        self.seen_expressions: Set[str] = set()\n",
    "        self.duplicate_expressions: List[str] = []\n",
    "        self.export_data = None\n",
    "    \n",
    "    def analyze_references(self, references: List[Dict]) -> None:\n",
    "        \"\"\"Analyze reference patterns and update statistics.\"\"\"\n",
    "        print(\"ðŸ“Š Analyzing references...\")\n",
    "        \n",
    "        self.stats['total_references'] = len(references)\n",
    "        \n",
    "        for i, ref in enumerate(references):\n",
    "            # Get the expression/URL from reference\n",
    "            expression = self._extract_expression(ref)\n",
    "            if not expression:\n",
    "                continue\n",
    "            \n",
    "            # Check if versioned\n",
    "            if is_versioned_url(expression):\n",
    "                self.stats['versioned_references'] += 1\n",
    "            else:\n",
    "                self.stats['unversioned_references'] += 1\n",
    "            \n",
    "            # Check reference type\n",
    "            ref_type = get_reference_type(expression)\n",
    "            if ref_type == 'concepts':\n",
    "                self.stats['concept_references'] += 1\n",
    "            elif ref_type == 'mappings':\n",
    "                self.stats['mapping_references'] += 1\n",
    "            else:\n",
    "                self.stats['other_references'] += 1\n",
    "        \n",
    "        print(\"âœ… Reference analysis complete!\")\n",
    "    \n",
    "    def _extract_expression(self, ref: Dict) -> str:\n",
    "        \"\"\"Extract the main expression/URL from a reference.\"\"\"\n",
    "        # Try common field names for the reference URL\n",
    "        possible_fields = ['expression', 'url', 'uri', 'reference_url']\n",
    "        \n",
    "        for field in possible_fields:\n",
    "            if field in ref and ref[field]:\n",
    "                return ref[field]\n",
    "        \n",
    "        # If it's in a nested structure\n",
    "        if 'data' in ref and 'expressions' in ref['data']:\n",
    "            expressions = ref['data']['expressions']\n",
    "            if expressions and len(expressions) > 0:\n",
    "                return expressions[0]\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    def _get_collection_url(self, ref: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Extract collection URL from export data.\n",
    "        \n",
    "        In OCL exports, the collection URL is available at:\n",
    "        - export_data['url'] = \"/users/jamlung/collections/squad-test-not-validation/\"\n",
    "        - export_data['collection']['url'] = \"/users/jamlung/collections/squad-test-not-validation/\"\n",
    "        \"\"\"\n",
    "        if not self.export_data:\n",
    "            print(\"   âš ï¸ Export data not available for collection URL extraction\")\n",
    "            return \"/collections/unknown/\"\n",
    "            \n",
    "        # Try main URL field first (this is the collection URL)\n",
    "        if 'url' in self.export_data:\n",
    "            collection_url = self.export_data['url']\n",
    "            # Ensure it ends with /\n",
    "            return collection_url if collection_url.endswith('/') else collection_url + '/'\n",
    "        \n",
    "        # Try nested collection.url field\n",
    "        if 'collection' in self.export_data and 'url' in self.export_data['collection']:\n",
    "            collection_url = self.export_data['collection']['url']\n",
    "            # Ensure it ends with /\n",
    "            return collection_url if collection_url.endswith('/') else collection_url + '/'\n",
    "        \n",
    "        print(\"   âš ï¸ Could not determine collection URL from export data\")\n",
    "        return \"/collections/unknown/\"\n",
    "    \n",
    "    def _is_duplicate_expression(self, expression: str) -> bool:\n",
    "        \"\"\"Check if expression is a duplicate and track it.\"\"\"\n",
    "        normalized = normalize_expression(expression)\n",
    "        \n",
    "        if normalized in self.seen_expressions:\n",
    "            self.stats['duplicates_found'] += 1\n",
    "            if self.config.REPORT_DUPLICATES:\n",
    "                self.duplicate_expressions.append(expression)\n",
    "            return True\n",
    "        \n",
    "        self.seen_expressions.add(normalized)\n",
    "        return False\n",
    "    \n",
    "    def process_references(self, references: List[Dict], export_data: Dict) -> Tuple[List[Dict], List[Dict]]:\n",
    "        \"\"\"\n",
    "        Process references to create unversioned equivalents and deletion commands.\n",
    "        ONLY processes versioned references for modernization.\n",
    "        \"\"\"\n",
    "        self.export_data = export_data\n",
    "        self.analyze_references(references)\n",
    "        \n",
    "        processed_references = []\n",
    "        references_to_delete = []\n",
    "        \n",
    "        print(f\"\\nðŸ”„ Processing {len(references)} references...\")\n",
    "        print(f\"   ðŸŽ¯ Strategy: Only modernize versioned references\")\n",
    "        print(f\"   ðŸš« Duplicate handling: {'Skip' if self.config.SKIP_DUPLICATES else 'Allow'}\")\n",
    "        \n",
    "        collection_url = self._get_collection_url({})\n",
    "        \n",
    "        for i, ref in enumerate(references, 1):\n",
    "            expression = self._extract_expression(ref)\n",
    "            if not expression:\n",
    "                print(f\"   âš ï¸ Warning: Could not extract expression from reference {i}\")\n",
    "                continue\n",
    "            \n",
    "            # âœ¨ KEY CHANGE: Only process versioned references\n",
    "            if not is_versioned_url(expression):\n",
    "                self.stats['references_unchanged'] += 1\n",
    "                continue  # Skip unversioned references\n",
    "            \n",
    "            self.stats['references_to_modernize'] += 1\n",
    "            \n",
    "            # Create unversioned equivalent\n",
    "            unversioned_expression = strip_version_from_url(expression)\n",
    "            \n",
    "            # Check for duplicates\n",
    "            if self.config.SKIP_DUPLICATES and self._is_duplicate_expression(unversioned_expression):\n",
    "                self.stats['duplicates_skipped'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Determine cascade settings\n",
    "            cascade_settings = None\n",
    "            if self.config.PRESERVE_ORIGINAL_CASCADE:\n",
    "                original_cascade = extract_cascade_from_reference(ref)\n",
    "                if original_cascade:\n",
    "                    cascade_settings = original_cascade\n",
    "                    self.stats['cascade_preserved'] += 1\n",
    "            \n",
    "            if cascade_settings is None:\n",
    "                cascade_settings = self.config.get_cascade_settings()\n",
    "                self.stats['cascade_preset'] += 1\n",
    "            \n",
    "            # Create unversioned reference\n",
    "            new_ref = {\n",
    "                \"type\": \"Reference\",\n",
    "                \"collection_url\": collection_url,\n",
    "                \"data\": {\n",
    "                    \"expressions\": [unversioned_expression]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add cascade if specified (only for concept references)\n",
    "            if cascade_settings and get_reference_type(unversioned_expression) == 'concepts':\n",
    "                new_ref[\"__cascade\"] = cascade_settings\n",
    "            \n",
    "            processed_references.append(new_ref)\n",
    "            \n",
    "            # Create deletion command for the versioned reference\n",
    "            delete_ref = {\n",
    "                \"type\": \"Reference\",\n",
    "                \"collection_url\": collection_url,\n",
    "                \"data\": {\n",
    "                    \"expressions\": [expression]  # Keep original versioned URL\n",
    "                },\n",
    "                \"__action\": \"DELETE\"\n",
    "                # Note: Intentionally NOT including cascade for deletes\n",
    "            }\n",
    "            references_to_delete.append(delete_ref)\n",
    "        \n",
    "        print(f\"\\nâœ… Processing complete!\")\n",
    "        print(f\"   ðŸ“¤ Unversioned references to add: {len(processed_references)}\")\n",
    "        print(f\"   ðŸ—‘ï¸ Versioned references to delete: {len(references_to_delete)}\")\n",
    "        print(f\"   âš¡ References left unchanged: {self.stats['references_unchanged']}\")\n",
    "        if self.stats['duplicates_skipped'] > 0:\n",
    "            print(f\"   ðŸš« Duplicates skipped: {self.stats['duplicates_skipped']}\")\n",
    "        \n",
    "        return processed_references, references_to_delete\n",
    "\n",
    "\n",
    "class ReportGenerator:\n",
    "    \"\"\"Generates detailed reports on the migration process.\"\"\"\n",
    "    \n",
    "    def __init__(self, processor: ReferenceProcessor):\n",
    "        self.processor = processor\n",
    "        self.stats = processor.stats\n",
    "    \n",
    "    def print_summary(self) -> None:\n",
    "        \"\"\"Print a summary to console.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ðŸ“Š MODERNIZATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ðŸ“ Total references: {self.stats['total_references']}\")\n",
    "        print(f\"   ðŸ§¬ Concepts: {self.stats['concept_references']}\")\n",
    "        print(f\"   ðŸ”— Mappings: {self.stats['mapping_references']}\")\n",
    "        print(f\"   â“ Other: {self.stats['other_references']}\")\n",
    "        print()\n",
    "        print(f\"ðŸ·ï¸ Reference Versions:\")\n",
    "        print(f\"   ðŸ“Œ Versioned (to modernize): {self.stats['versioned_references']}\")\n",
    "        print(f\"   ðŸ“„ Already unversioned: {self.stats['unversioned_references']}\")\n",
    "        print()\n",
    "        print(f\"âš™ï¸ Cascade Handling:\")\n",
    "        print(f\"   ðŸ’¾ Original preserved: {self.stats['cascade_preserved']}\")\n",
    "        print(f\"   ðŸ”§ Preset applied: {self.stats['cascade_preset']}\")\n",
    "        print()\n",
    "        print(f\"ðŸš« Duplicate Handling:\")\n",
    "        print(f\"   ðŸ” Duplicates found: {self.stats['duplicates_found']}\")\n",
    "        print(f\"   â­ï¸ Duplicates skipped: {self.stats['duplicates_skipped']}\")\n",
    "        print()\n",
    "        print(f\"ðŸ“ˆ Migration Impact:\")\n",
    "        print(f\"   ðŸ—‘ï¸ References to remove: {self.stats['references_to_modernize']}\")\n",
    "        print(f\"   âž• References to add: {len(self.processor.seen_expressions) - self.stats['duplicates_skipped']}\")\n",
    "        print(f\"   âš¡ References unchanged: {self.stats['references_unchanged']}\")\n",
    "        print(f\"   ðŸ“Š Net change: +{len(self.processor.seen_expressions) - self.stats['duplicates_skipped'] - self.stats['references_to_modernize']}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Show duplicate examples if any\n",
    "        if self.processor.duplicate_expressions:\n",
    "            print(f\"\\nðŸš« Duplicate expressions found (showing first 5):\")\n",
    "            for i, expr in enumerate(self.processor.duplicate_expressions[:5]):\n",
    "                print(f\"   {i+1}. {expr}\")\n",
    "            if len(self.processor.duplicate_expressions) > 5:\n",
    "                print(f\"   ... and {len(self.processor.duplicate_expressions) - 5} more\")\n",
    "    \n",
    "    def generate_report(self, output_file: str) -> None:\n",
    "        \"\"\"Generate a detailed migration report.\"\"\"\n",
    "        report_lines = [\n",
    "            \"OCL Reference Modernizer - Migration Report\",\n",
    "            \"=\" * 50,\n",
    "            f\"Generated: {datetime.now().isoformat()}\",\n",
    "            f\"GitHub Issue: https://github.com/OpenConceptLab/ocl_issues/issues/2212\",\n",
    "            f\"Cascade Preset: {self.processor.config.CASCADE_PRESET}\",\n",
    "            \"\",\n",
    "            \"REFERENCE ANALYSIS\",\n",
    "            \"-\" * 20,\n",
    "            f\"Total references found: {self.stats['total_references']}\",\n",
    "            f\"Versioned references (to modernize): {self.stats['versioned_references']}\",\n",
    "            f\"Already unversioned (unchanged): {self.stats['unversioned_references']}\",\n",
    "            f\"References processed: {self.stats['references_to_modernize']}\",\n",
    "            \"\",\n",
    "            \"REFERENCE TYPES\",\n",
    "            \"-\" * 15,\n",
    "            f\"Concept references: {self.stats['concept_references']}\",\n",
    "            f\"Mapping references: {self.stats['mapping_references']}\",\n",
    "            f\"Other references: {self.stats['other_references']}\",\n",
    "            \"\",\n",
    "            \"CASCADE HANDLING\",\n",
    "            \"-\" * 15,\n",
    "            f\"Original cascade preserved: {self.stats['cascade_preserved']}\",\n",
    "            f\"Preset cascade applied: {self.stats['cascade_preset']}\",\n",
    "            \"\",\n",
    "            \"DUPLICATE HANDLING\",\n",
    "            \"-\" * 17,\n",
    "            f\"Duplicates found: {self.stats['duplicates_found']}\",\n",
    "            f\"Duplicates skipped: {self.stats['duplicates_skipped']}\",\n",
    "            \"\",\n",
    "            \"MIGRATION SUMMARY\",\n",
    "            \"-\" * 17,\n",
    "            f\"References to be deleted: {self.stats['references_to_modernize']}\",\n",
    "            f\"New unversioned references: {len(self.processor.seen_expressions) - self.stats['duplicates_skipped']}\",\n",
    "            f\"References left unchanged: {self.stats['references_unchanged']}\",\n",
    "            f\"Net change in references: {len(self.processor.seen_expressions) - self.stats['duplicates_skipped'] - self.stats['references_to_modernize']}\",\n",
    "            \"\",\n",
    "            \"NEXT STEPS\",\n",
    "            \"-\" * 10,\n",
    "            \"1. Review generated JSONL files\",\n",
    "            \"2. Test import on a backup/test collection first\",\n",
    "            \"3. Use OCL's Bulk Import Interface\",\n",
    "            \"4. Import deletion file FIRST to remove versioned references\",\n",
    "            \"5. Import unversioned references file SECOND\",\n",
    "            \"6. Verify collection state and expansions\"\n",
    "        ]\n",
    "        \n",
    "        # Add duplicate details if any\n",
    "        if self.processor.duplicate_expressions:\n",
    "            report_lines.extend([\n",
    "                \"\",\n",
    "                \"DUPLICATE EXPRESSIONS FOUND\",\n",
    "                \"-\" * 27\n",
    "            ])\n",
    "            for expr in self.processor.duplicate_expressions[:20]:\n",
    "                report_lines.append(f\"- {expr}\")\n",
    "            if len(self.processor.duplicate_expressions) > 20:\n",
    "                report_lines.append(f\"... and {len(self.processor.duplicate_expressions) - 20} more\")\n",
    "        \n",
    "        try:\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write('\\n'.join(report_lines))\n",
    "            print(f\"ðŸ“„ Migration report saved to: {output_file}\")\n",
    "        except IOError as e:\n",
    "            print(f\"âŒ Error saving report: {e}\")\n",
    "\n",
    "print(\"ðŸ”§ Processing classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load and Validate Input File\n",
    "\n",
    "**ðŸ“ Let's load your OCL export file and see what we're working with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Checking input file: input-example-jamlung/export.json\n",
      "ðŸ“¥ Loading collection export from: input-example-jamlung/export.json\n",
      "âœ… Export file loaded successfully\n",
      "ðŸ“Š File size: 180,743 bytes (0.2 MB)\n",
      "ðŸ”‘ Top-level keys in export: ['type', 'uuid', 'id', 'short_code', 'name', 'full_name', 'description', 'collection_type', 'custom_validation_schema', 'public_access', 'default_locale', 'supported_locales', 'website', 'url', 'owner', 'owner_type', 'owner_url', 'version_url', 'previous_version_url', 'created_on', 'updated_on', 'created_by', 'updated_by', 'extras', 'external_id', 'version', 'concepts_url', 'mappings_url', 'expansions_url', 'is_processing', 'released', 'retired', 'canonical_url', 'identifier', 'publisher', 'contact', 'jurisdiction', 'purpose', 'copyright', 'meta', 'immutable', 'revision_date', 'text', 'experimental', 'locked_date', 'autoexpand', 'expansion_url', 'checksums', 'collection', 'concepts', 'references', 'mappings', 'export_time']\n",
      "ðŸ  Collection URL: /users/jamlung/collections/facility-test/\n",
      "ðŸ“› Collection name: facility-test\n",
      "\n",
      "âœ… Export file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check if input file exists and load it\n",
    "print(f\"ðŸ“ Checking input file: {config.INPUT_FILE}\")\n",
    "\n",
    "if not os.path.exists(config.INPUT_FILE):\n",
    "    print(f\"âŒ File not found: {config.INPUT_FILE}\")\n",
    "    print(\"\\nðŸ“‹ Please:\")\n",
    "    print(\"   1. Export your OCL collection to JSON format\")\n",
    "    print(\"   2. Update the INPUT_FILE path in the Configuration cell\")\n",
    "    print(\"   3. Re-run this cell\")\n",
    "    export_data = None\n",
    "else:\n",
    "    try:\n",
    "        # Load the export file\n",
    "        export_data = load_collection_export(config.INPUT_FILE)\n",
    "        \n",
    "        # Show basic file info\n",
    "        file_size = os.path.getsize(config.INPUT_FILE)\n",
    "        print(f\"ðŸ“Š File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n",
    "        \n",
    "        # Show top-level keys in export\n",
    "        if isinstance(export_data, dict):\n",
    "            print(f\"ðŸ”‘ Top-level keys in export: {list(export_data.keys())}\")\n",
    "        \n",
    "        # Show collection info\n",
    "        if 'url' in export_data:\n",
    "            print(f\"ðŸ  Collection URL: {export_data['url']}\")\n",
    "        if 'name' in export_data:\n",
    "            print(f\"ðŸ“› Collection name: {export_data['name']}\")\n",
    "        \n",
    "        print(\"\\nâœ… Export file loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading file: {e}\")\n",
    "        export_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extract References from Export\n",
    "\n",
    "**ðŸ“¤ Now let's extract the references from your export file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Extracting references from export data...\n",
      "   âœ… Found 21 references\n",
      "   ðŸ“‹ Sample reference keys: ['expression', 'reference_type', 'id', 'last_resolved_at', 'uri', 'uuid', 'include', 'type', 'code', 'resource_version', 'namespace', 'system', 'version', 'valueset', 'cascade', 'filter', 'display', 'created_at', 'updated_at', 'concepts', 'mappings', 'translation', 'transform']\n",
      "   ðŸ“‹ Sample expression: /users/jamlung/sources/zim_demo/concepts/12/\n",
      "\n",
      "ðŸŽ¯ Success! Found 21 references to analyze.\n",
      "\n",
      "ðŸ“‹ Sample reference structure:\n",
      "   expression: /users/jamlung/sources/zim_demo/concepts/12/\n",
      "   reference_type: concepts\n",
      "   id: 11654253\n",
      "   last_resolved_at: 2025-08-20T14:50:33.697777Z\n",
      "   uri: /users/jamlung/collections/facility-test/script-te...\n",
      "   uuid: 11654253\n",
      "   include: True\n",
      "   type: CollectionReference\n",
      "   code: 12\n",
      "   resource_version: None\n",
      "   namespace: None\n",
      "   system: /users/jamlung/sources/zim_demo/\n",
      "   version: None\n",
      "   valueset: None\n",
      "   cascade: {'method': 'sourcetoconcepts', 'map_types': 'Q-AND-A,CONCEPT-SET', 'cascade_levels': '*', 'return_map_types': '*'}\n",
      "   filter: None\n",
      "   display: None\n",
      "   created_at: 2025-08-20T14:50:33.700951Z\n",
      "   updated_at: 2025-08-20T14:50:33.700969Z\n",
      "   concepts: 11\n",
      "   mappings: 62\n",
      "   translation: Include latest concept \"12\" from jamlung/zim_demo ...\n",
      "   transform: \n",
      "\n",
      "ðŸ” Quick analysis:\n",
      "   ðŸ“Œ Versioned references: 18\n",
      "   ðŸ“„ Unversioned references: 3\n"
     ]
    }
   ],
   "source": [
    "if export_data is None:\n",
    "    print(\"âŒ No export data available. Please fix the input file issue above.\")\n",
    "    references = []\n",
    "else:\n",
    "    try:\n",
    "        # Extract references from the export\n",
    "        references = extract_references_from_export(export_data)\n",
    "        \n",
    "        if not references:\n",
    "            print(\"âš ï¸ No references found in export file.\")\n",
    "            print(\"\\nðŸ“‹ Export structure:\")\n",
    "            if isinstance(export_data, dict):\n",
    "                for key in export_data.keys():\n",
    "                    value = export_data[key]\n",
    "                    if isinstance(value, list):\n",
    "                        print(f\"   ðŸ“‹ {key}: {len(value)} items\")\n",
    "                    else:\n",
    "                        print(f\"   ðŸ“ {key}: {type(value).__name__}\")\n",
    "        else:\n",
    "            print(f\"\\nðŸŽ¯ Success! Found {len(references)} references to analyze.\")\n",
    "            \n",
    "            # Show sample reference structure\n",
    "            if references:\n",
    "                print(\"\\nðŸ“‹ Sample reference structure:\")\n",
    "                sample_ref = references[0]\n",
    "                for key, value in sample_ref.items():\n",
    "                    if isinstance(value, str) and len(value) > 50:\n",
    "                        print(f\"   {key}: {value[:50]}...\")\n",
    "                    else:\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                        \n",
    "                # Quick analysis\n",
    "                versioned_count = sum(1 for ref in references if 'expression' in ref and is_versioned_url(ref['expression']))\n",
    "                print(f\"\\nðŸ” Quick analysis:\")\n",
    "                print(f\"   ðŸ“Œ Versioned references: {versioned_count}\")\n",
    "                print(f\"   ðŸ“„ Unversioned references: {len(references) - versioned_count}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error extracting references: {e}\")\n",
    "        references = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Process References\n",
    "\n",
    "**âš™ï¸ Now let's process the references and generate the modernized versions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Analyzing references...\n",
      "âœ… Reference analysis complete!\n",
      "\n",
      "ðŸ”„ Processing 21 references...\n",
      "   ðŸŽ¯ Strategy: Only modernize versioned references\n",
      "   ðŸš« Duplicate handling: Skip\n",
      "\n",
      "âœ… Processing complete!\n",
      "   ðŸ“¤ Unversioned references to add: 18\n",
      "   ðŸ—‘ï¸ Versioned references to delete: 18\n",
      "   âš¡ References left unchanged: 3\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š MODERNIZATION SUMMARY\n",
      "============================================================\n",
      "ðŸ“ Total references: 21\n",
      "   ðŸ§¬ Concepts: 6\n",
      "   ðŸ”— Mappings: 15\n",
      "   â“ Other: 0\n",
      "\n",
      "ðŸ·ï¸ Reference Versions:\n",
      "   ðŸ“Œ Versioned (to modernize): 18\n",
      "   ðŸ“„ Already unversioned: 3\n",
      "\n",
      "âš™ï¸ Cascade Handling:\n",
      "   ðŸ’¾ Original preserved: 0\n",
      "   ðŸ”§ Preset applied: 18\n",
      "\n",
      "ðŸš« Duplicate Handling:\n",
      "   ðŸ” Duplicates found: 0\n",
      "   â­ï¸ Duplicates skipped: 0\n",
      "\n",
      "ðŸ“ˆ Migration Impact:\n",
      "   ðŸ—‘ï¸ References to remove: 18\n",
      "   âž• References to add: 18\n",
      "   âš¡ References unchanged: 3\n",
      "   ðŸ“Š Net change: +0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if not references:\n",
    "    print(\"âŒ No references to process. Please check the steps above.\")\n",
    "    processor = None\n",
    "    processed_references = []\n",
    "    references_to_delete = []\n",
    "else:\n",
    "    try:\n",
    "        # Initialize the processor\n",
    "        processor = ReferenceProcessor(config)\n",
    "        \n",
    "        # Process the references\n",
    "        processed_references, references_to_delete = processor.process_references(references, export_data)\n",
    "        \n",
    "        # Show detailed results\n",
    "        report_generator = ReportGenerator(processor)\n",
    "        report_generator.print_summary()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing references: {e}\")\n",
    "        processor = None\n",
    "        processed_references = []\n",
    "        references_to_delete = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Output Files\n",
    "\n",
    "**ðŸ’¾ Let's save the results to files for OCL bulk import:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saving output files...\n",
      "ðŸ“‚ Output directory: output\n",
      "ðŸ’¾ Saved 18 items to output\\unversioned_references_20250820_105615.json\n",
      "ðŸ’¾ Saved 18 items to output\\references_to_delete_20250820_105615.json\n",
      "ðŸ“„ Migration report saved to: output\\migration_report_20250820_105615.txt\n",
      "\n",
      "âœ… All files saved successfully!\n",
      "\n",
      "ðŸ“ Generated files:\n",
      "   ðŸ“¤ Unversioned references: output\\unversioned_references_20250820_105615.json\n",
      "   ðŸ—‘ï¸ References to delete: output\\references_to_delete_20250820_105615.json\n",
      "   ðŸ“„ Migration report: output\\migration_report_20250820_105615.txt\n"
     ]
    }
   ],
   "source": [
    "if not processed_references and not references_to_delete:\n",
    "    print(\"âŒ No processed references to save. Please check the processing step above.\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"ðŸ’¾ Saving output files...\")\n",
    "        \n",
    "        # Create output directory\n",
    "        output_dir = config.OUTPUT_DIR\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"ðŸ“‚ Output directory: {output_dir}\")\n",
    "        \n",
    "        # Generate file paths\n",
    "        unversioned_path = os.path.join(output_dir, config.UNVERSIONED_FILE)\n",
    "        delete_path = os.path.join(output_dir, config.DELETE_FILE)\n",
    "        report_path = os.path.join(output_dir, config.REPORT_FILE)\n",
    "        \n",
    "        # Save the files\n",
    "        if processed_references:\n",
    "            save_jsonl(processed_references, unversioned_path)\n",
    "        else:\n",
    "            print(\"   â„¹ï¸ No unversioned references to save (no versioned references found)\")\n",
    "            \n",
    "        if references_to_delete:\n",
    "            save_jsonl(references_to_delete, delete_path)\n",
    "        else:\n",
    "            print(\"   â„¹ï¸ No references to delete (no versioned references found)\")\n",
    "        \n",
    "        # Generate detailed report\n",
    "        if processor:\n",
    "            report_generator = ReportGenerator(processor)\n",
    "            report_generator.generate_report(report_path)\n",
    "        \n",
    "        print(\"\\nâœ… All files saved successfully!\")\n",
    "        print(f\"\\nðŸ“ Generated files:\")\n",
    "        if processed_references:\n",
    "            print(f\"   ðŸ“¤ Unversioned references: {unversioned_path}\")\n",
    "        if references_to_delete:\n",
    "            print(f\"   ðŸ—‘ï¸ References to delete: {delete_path}\")\n",
    "        print(f\"   ðŸ“„ Migration report: {report_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Preview Generated Files\n",
    "\n",
    "**ðŸ‘€ Let's take a look at what we generated:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘ï¸ Previewing generated files...\n",
      "\n",
      "ðŸ“„ Preview of unversioned_references_20250820_105615.json (first 2 lines):\n",
      "--------------------------------------------------\n",
      "Line 1:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/314250/\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "Line 2:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/312829/\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "ðŸ“„ Preview of references_to_delete_20250820_105615.json (first 2 lines):\n",
      "--------------------------------------------------\n",
      "Line 1:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/314250/5406810/\"\n",
      "    ]\n",
      "  },\n",
      "  \"__action\": \"DELETE\"\n",
      "}\n",
      "\n",
      "Line 2:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/312829/5386191/\"\n",
      "    ]\n",
      "  },\n",
      "  \"__action\": \"DELETE\"\n",
      "}\n",
      "\n",
      "ðŸ“Š unversioned_references_20250820_105615.json: 18 lines, 3,346 bytes\n",
      "ðŸ“Š references_to_delete_20250820_105615.json: 18 lines, 3,370 bytes\n"
     ]
    }
   ],
   "source": [
    "def display_file_preview(filename: str, num_lines: int = 3) -> None:\n",
    "    \"\"\"Display preview of a JSONL file.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"\\nðŸ“„ Preview of {os.path.basename(filename)} (first {num_lines} lines):\")\n",
    "            print(\"-\" * 50)\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                for i, line in enumerate(f):\n",
    "                    if i < num_lines:\n",
    "                        try:\n",
    "                            data = json.loads(line.strip())\n",
    "                            print(f\"Line {i+1}:\")\n",
    "                            print(json.dumps(data, indent=2))\n",
    "                            print()\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(f\"Line {i+1}: {line.strip()}\")\n",
    "                    else:\n",
    "                        break\n",
    "        else:\n",
    "            print(f\"âŒ File not found: {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"âŒ Error reading {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Preview the generated files\n",
    "if config.OUTPUT_DIR:\n",
    "    unversioned_path = os.path.join(config.OUTPUT_DIR, config.UNVERSIONED_FILE)\n",
    "    delete_path = os.path.join(config.OUTPUT_DIR, config.DELETE_FILE)\n",
    "    \n",
    "    print(\"ðŸ‘ï¸ Previewing generated files...\")\n",
    "    \n",
    "    if os.path.exists(unversioned_path):\n",
    "        display_file_preview(unversioned_path, 2)\n",
    "    else:\n",
    "        print(f\"\\nâ„¹ï¸ {os.path.basename(unversioned_path)} not created (no versioned references to modernize)\")\n",
    "        \n",
    "    if os.path.exists(delete_path):\n",
    "        display_file_preview(delete_path, 2)\n",
    "    else:\n",
    "        print(f\"\\nâ„¹ï¸ {os.path.basename(delete_path)} not created (no versioned references to delete)\")\n",
    "    \n",
    "    # Show file sizes\n",
    "    for filepath in [unversioned_path, delete_path]:\n",
    "        if os.path.exists(filepath):\n",
    "            size = os.path.getsize(filepath)\n",
    "            with open(filepath, 'r') as f:\n",
    "                lines = sum(1 for _ in f)\n",
    "            print(f\"ðŸ“Š {os.path.basename(filepath)}: {lines} lines, {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Validation & Next Steps\n",
    "\n",
    "**âœ… Let's validate our results and plan next steps:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” VALIDATION CHECKLIST\n",
      "========================================\n",
      "âœ… ðŸ“Š References found\n",
      "âœ… ðŸ·ï¸ Versioned refs identified\n",
      "âœ… ðŸ”§ Processing completed\n",
      "âœ… ðŸš« Duplicate handling configured\n",
      "âœ… âš™ï¸ Cascade handling configured\n",
      "\n",
      "ðŸ“‹ STATISTICS SUMMARY:\n",
      "   ðŸ“ Total references: 21\n",
      "   ðŸ§¬ Concept references: 6\n",
      "   ðŸ”— Mapping references: 15\n",
      "   ðŸ“Œ Versioned (to modernize): 18\n",
      "   ðŸ“„ Already unversioned: 3\n",
      "   ðŸš« Duplicates handled: 0 found, 0 skipped\n",
      "\n",
      "ðŸŽ¯ EXPECTED RESULTS AFTER MIGRATION:\n",
      "   ðŸ—‘ï¸ References to be deleted: 18\n",
      "   âž• References to be added: 18\n",
      "   âš¡ References left unchanged: 3\n",
      "   ðŸ“Š Net change: 0\n",
      "\n",
      "========================================\n",
      "ðŸš€ NEXT STEPS\n",
      "========================================\n",
      "1. ðŸ“‹ Review the migration report and file previews above\n",
      "2. ðŸ’¾ Backup your OCL collection (create a version)\n",
      "3. ðŸ§ª Test on a backup/test collection first (recommended)\n",
      "4. ðŸŒ Use OCL's Bulk Import Interface:\n",
      "   a. Import the DELETE file FIRST\n",
      "   b. Then import the unversioned references file\n",
      "5. âœ… Verify collection state and functionality\n",
      "6. ðŸ“Š Check collection expansion results\n",
      "\n",
      "âš ï¸ IMPORTANT REMINDERS:\n",
      "   â€¢ Always backup before applying changes\n",
      "   â€¢ Test on a small collection first\n",
      "   â€¢ Apply deletions BEFORE additions\n",
      "   â€¢ Validate results thoroughly\n",
      "\n",
      "ðŸ“ Your files are ready in: output/\n",
      "   ðŸ• Generated at: 20250820_105615\n",
      "   ðŸŽ›ï¸ Using cascade preset: OPENMRS_WITHOUT_TRANSFORM\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” VALIDATION CHECKLIST\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if we have valid results\n",
    "if processor and hasattr(processor, 'stats'):\n",
    "    stats = processor.stats\n",
    "    \n",
    "    # Validation checks\n",
    "    checks = [\n",
    "        (\"ðŸ“Š References found\", stats['total_references'] > 0),\n",
    "        (\"ðŸ·ï¸ Versioned refs identified\", stats['versioned_references'] >= 0),\n",
    "        (\"ðŸ”§ Processing completed\", True),  # If we got here, processing completed\n",
    "        (\"ðŸš« Duplicate handling configured\", config.SKIP_DUPLICATES),\n",
    "        (\"âš™ï¸ Cascade handling configured\", True),  # Always true if we got this far\n",
    "    ]\n",
    "    \n",
    "    for check_name, passed in checks:\n",
    "        status = \"âœ…\" if passed else \"âŒ\"\n",
    "        print(f\"{status} {check_name}\")\n",
    "    \n",
    "    print(\"\\nðŸ“‹ STATISTICS SUMMARY:\")\n",
    "    print(f\"   ðŸ“ Total references: {stats['total_references']}\")\n",
    "    print(f\"   ðŸ§¬ Concept references: {stats['concept_references']}\")\n",
    "    print(f\"   ðŸ”— Mapping references: {stats['mapping_references']}\")\n",
    "    print(f\"   ðŸ“Œ Versioned (to modernize): {stats['versioned_references']}\")\n",
    "    print(f\"   ðŸ“„ Already unversioned: {stats['unversioned_references']}\")\n",
    "    print(f\"   ðŸš« Duplicates handled: {stats['duplicates_found']} found, {stats['duplicates_skipped']} skipped\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ EXPECTED RESULTS AFTER MIGRATION:\")\n",
    "    if stats['versioned_references'] > 0:\n",
    "        print(f\"   ðŸ—‘ï¸ References to be deleted: {stats['references_to_modernize']}\")\n",
    "        print(f\"   âž• References to be added: {len(processed_references)}\")\n",
    "        print(f\"   âš¡ References left unchanged: {stats['references_unchanged']}\")\n",
    "        print(f\"   ðŸ“Š Net change: {len(processed_references) - stats['references_to_modernize']}\")\n",
    "    else:\n",
    "        print(f\"   â„¹ï¸ No versioned references found - collection is already modernized!\")\n",
    "        print(f\"   ðŸ“Š All {stats['total_references']} references are already unversioned\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No valid processing results to validate.\")\n",
    "    print(\"   Please check the previous steps for errors.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"ðŸš€ NEXT STEPS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if processor and processor.stats['versioned_references'] > 0:\n",
    "    print(\"1. ðŸ“‹ Review the migration report and file previews above\")\n",
    "    print(\"2. ðŸ’¾ Backup your OCL collection (create a version)\")\n",
    "    print(\"3. ðŸ§ª Test on a backup/test collection first (recommended)\")\n",
    "    print(\"4. ðŸŒ Use OCL's Bulk Import Interface:\")\n",
    "    print(\"   a. Import the DELETE file FIRST\")\n",
    "    print(\"   b. Then import the unversioned references file\")\n",
    "    print(\"5. âœ… Verify collection state and functionality\")\n",
    "    print(\"6. ðŸ“Š Check collection expansion results\")\n",
    "else:\n",
    "    print(\"ðŸŽ‰ Great news! Your collection is already modernized.\")\n",
    "    print(\"   âœ… All references are already unversioned\")\n",
    "    print(\"   ðŸ“Š No migration needed\")\n",
    "\n",
    "print(\"\\nâš ï¸ IMPORTANT REMINDERS:\")\n",
    "print(\"   â€¢ Always backup before applying changes\")\n",
    "print(\"   â€¢ Test on a small collection first\")\n",
    "print(\"   â€¢ Apply deletions BEFORE additions\")\n",
    "print(\"   â€¢ Validate results thoroughly\")\n",
    "\n",
    "if config.OUTPUT_DIR:\n",
    "    print(f\"\\nðŸ“ Your files are ready in: {config.OUTPUT_DIR}/\")\n",
    "    print(f\"   ðŸ• Generated at: {config.TIMESTAMP}\")\n",
    "    print(f\"   ðŸŽ›ï¸ Using cascade preset: {config.CASCADE_PRESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully analyzed your OCL collection references and generated modernization files (if needed)!\n",
    "\n",
    "### ðŸ“ Generated Files:\n",
    "- **`unversioned_references_*.json`** - Import this to add modernized references (if versioned refs found)\n",
    "- **`references_to_delete_*.json`** - Import this FIRST to remove old versioned references (if any)  \n",
    "- **`migration_report_*.txt`** - Detailed report with statistics and instructions\n",
    "\n",
    "### âœ¨ Key Improvements in This Version:\n",
    "- **ðŸŽ¯ Smart Processing**: Only modernizes versioned references, leaves unversioned ones unchanged\n",
    "- **ðŸš« Duplicate Prevention**: Detects and optionally skips duplicate expressions\n",
    "- **ðŸŽ›ï¸ Cascade Presets**: Support for OpenMRS and custom cascade configurations\n",
    "- **ðŸ“Š Better Reporting**: More detailed statistics and validation\n",
    "\n",
    "### ðŸ”— Useful Links:\n",
    "- **GitHub Issue**: [#2212](https://github.com/OpenConceptLab/ocl_issues/issues/2212)\n",
    "- **OCL Bulk Import Docs**: [OCL API Reference](https://docs.openconceptlab.org/en/latest/oclapi/apireference/bulkimporting.html)\n",
    "- **Cascade Documentation**: [OCL Cascade Reference](https://docs.openconceptlab.org/en/latest/oclapi/apireference/cascade.html)\n",
    "\n",
    "### âš ï¸ Remember:\n",
    "1. **Backup first** - Create a version of your collection before importing\n",
    "2. **Test first** - Try on a test collection before production\n",
    "3. **Order matters** - Import deletions before additions\n",
    "4. **Validate** - Check your collection expansion after migration\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook implements the enhanced OCL Reference Modernizer as specified in GitHub issue #2212, with improved behavior for processing only versioned references, preventing duplicates, and supporting cascade presets.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
