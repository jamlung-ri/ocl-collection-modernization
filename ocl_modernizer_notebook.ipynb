{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCL Reference Modernizer\n",
    "\n",
    "**GitHub Issue**: [#2212](https://github.com/OpenConceptLab/ocl_issues/issues/2212)\n",
    "\n",
    "## Overview\n",
    "This notebook modernizes OCL (Open Concept Lab) collection references by:\n",
    "1. 📥 Loading references from OCL collection version export JSON\n",
    "2. 🔍 Identifying versioned references using URL pattern matching\n",
    "3. ✨ Generating unversioned equivalents ONLY for versioned references\n",
    "4. 📤 Creating bulk import/delete files in JSONL format for OCL API\n",
    "5. 🔧 Supporting multiple cascade presets (OpenMRS, Custom, etc.)\n",
    "6. 🚫 Preventing duplicate expressions\n",
    "7. 📊 Reporting detailed statistics on the transformation\n",
    "\n",
    "## Acceptance Criteria ✅\n",
    "- ✅ Parse references from OCL collection version export JSON\n",
    "- ✅ Identify versioned references using URL pattern matching\n",
    "- ✅ Generate unversioned equivalents ONLY for versioned references\n",
    "- ✅ Create bulk import/delete JSONL files\n",
    "- ✅ Handle cascade configuration with presets\n",
    "- ✅ Prevent duplicate expressions\n",
    "- ✅ Report concept/mapping reference counts\n",
    "\n",
    "## Instructions\n",
    "1. **Run cells sequentially** from top to bottom\n",
    "2. **Configure your settings** in the Configuration cell\n",
    "3. **Set your input file path** to your OCL export JSON\n",
    "4. **Choose cascade preset** (OpenMRS, Custom, etc.)\n",
    "5. **Review outputs** before applying to your collection\n",
    "6. **Use OCL's Bulk Import Interface** to apply the generated files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All packages imported successfully!\n",
      "🕐 Notebook started at: 2025-08-20 10:56:15\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional, Set\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "print(\"✅ All packages imported successfully!\")\n",
    "print(f\"🕐 Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration\n",
    "\n",
    "**🔧 Configure your settings here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Configuration loaded:\n",
      "   📁 Input file: input-example-jamlung/export.json\n",
      "   📂 Output directory: output\n",
      "   🕐 Timestamp: 20250820_105615\n",
      "   🔧 Preserve cascade: True\n",
      "   🎛️ Cascade preset: OPENMRS_WITHOUT_TRANSFORM\n",
      "   🚫 Skip duplicates: True\n",
      "\n",
      "⚠️ Make sure to update INPUT_FILE with your actual export file path!\n",
      "⚠️ Choose your CASCADE_PRESET based on your needs!\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - CUSTOMIZE THESE SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "class CascadePresets:\n",
    "    \"\"\"Predefined cascade configurations for different use cases.\"\"\"\n",
    "    \n",
    "    # OpenMRS cascade with transform\n",
    "    OPENMRS_WITH_TRANSFORM = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET\",\n",
    "        \"cascade_levels\": \"*\",\n",
    "        \"return_map_types\": \"*\",\n",
    "        \"transform\": \"openmrs\"\n",
    "    }\n",
    "    \n",
    "    # OpenMRS cascade without transform\n",
    "    OPENMRS_WITHOUT_TRANSFORM = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET\",\n",
    "        \"cascade_levels\": \"*\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "    \n",
    "    # Source to mappings only\n",
    "    SOURCE_TO_MAPPINGS = {\n",
    "        \"method\": \"sourcetomappings\",\n",
    "        \"map_types\": \"*\",\n",
    "        \"cascade_levels\": \"1\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "    \n",
    "    # No cascade (simple references)\n",
    "    NO_CASCADE = None\n",
    "    \n",
    "    # Custom cascade (to be defined by user)\n",
    "    CUSTOM = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET\",\n",
    "        \"cascade_levels\": \"*\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the reference modernizer.\"\"\"\n",
    "    \n",
    "    # 📁 INPUT FILE - SET THIS TO YOUR OCL EXPORT JSON FILE\n",
    "    INPUT_FILE = \"input-example-jamlung/export.json\"  # ⚠️ CHANGE THIS TO YOUR FILE PATH\n",
    "    \n",
    "    # 📂 Output Settings\n",
    "    OUTPUT_DIR = \"output\"\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 📄 File naming\n",
    "    UNVERSIONED_FILE = f\"unversioned_references_{TIMESTAMP}.json\"\n",
    "    DELETE_FILE = f\"references_to_delete_{TIMESTAMP}.json\"\n",
    "    REPORT_FILE = f\"migration_report_{TIMESTAMP}.txt\"\n",
    "    \n",
    "    # 🔧 Processing Options\n",
    "    PRESERVE_ORIGINAL_CASCADE = True  # Try to preserve original cascade settings\n",
    "    PRESERVE_REFERENCE_TYPE = True    # Preserve original reference type from export\n",
    "    \n",
    "    # 🎛️ Cascade Configuration\n",
    "    # Choose from: OPENMRS_WITH_TRANSFORM, OPENMRS_WITHOUT_TRANSFORM, \n",
    "    #              SOURCE_TO_MAPPINGS, NO_CASCADE, CUSTOM\n",
    "    CASCADE_PRESET = \"OPENMRS_WITHOUT_TRANSFORM\"  # 🔄 CHANGE THIS AS NEEDED\n",
    "    \n",
    "    # 🎨 Custom cascade settings (only used if CASCADE_PRESET = \"CUSTOM\")\n",
    "    CUSTOM_CASCADE = {\n",
    "        \"method\": \"sourcetoconcepts\",\n",
    "        \"map_types\": \"Q-AND-A,CONCEPT-SET,SAME-AS\",\n",
    "        \"cascade_levels\": \"2\",\n",
    "        \"return_map_types\": \"*\"\n",
    "    }\n",
    "    \n",
    "    # 🚫 Duplicate handling\n",
    "    SKIP_DUPLICATES = True  # Skip references with duplicate expressions\n",
    "    REPORT_DUPLICATES = True  # Report duplicate expressions found\n",
    "\n",
    "    def get_cascade_settings(self) -> Optional[Dict]:\n",
    "        \"\"\"Get the cascade settings based on the selected preset.\"\"\"\n",
    "        if self.CASCADE_PRESET == \"OPENMRS_WITH_TRANSFORM\":\n",
    "            return CascadePresets.OPENMRS_WITH_TRANSFORM\n",
    "        elif self.CASCADE_PRESET == \"OPENMRS_WITHOUT_TRANSFORM\":\n",
    "            return CascadePresets.OPENMRS_WITHOUT_TRANSFORM\n",
    "        elif self.CASCADE_PRESET == \"SOURCE_TO_MAPPINGS\":\n",
    "            return CascadePresets.SOURCE_TO_MAPPINGS\n",
    "        elif self.CASCADE_PRESET == \"NO_CASCADE\":\n",
    "            return CascadePresets.NO_CASCADE\n",
    "        elif self.CASCADE_PRESET == \"CUSTOM\":\n",
    "            return self.CUSTOM_CASCADE\n",
    "        else:\n",
    "            print(f\"⚠️ Unknown cascade preset: {self.CASCADE_PRESET}, using OpenMRS default\")\n",
    "            return CascadePresets.OPENMRS_WITHOUT_TRANSFORM\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"⚙️ Configuration loaded:\")\n",
    "print(f\"   📁 Input file: {config.INPUT_FILE}\")\n",
    "print(f\"   📂 Output directory: {config.OUTPUT_DIR}\")\n",
    "print(f\"   🕐 Timestamp: {config.TIMESTAMP}\")\n",
    "print(f\"   🔧 Preserve cascade: {config.PRESERVE_ORIGINAL_CASCADE}\")\n",
    "print(f\"   🎛️ Cascade preset: {config.CASCADE_PRESET}\")\n",
    "print(f\"   🚫 Skip duplicates: {config.SKIP_DUPLICATES}\")\n",
    "print()\n",
    "print(\"⚠️ Make sure to update INPUT_FILE with your actual export file path!\")\n",
    "print(\"⚠️ Choose your CASCADE_PRESET based on your needs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Utility functions defined successfully!\n",
      "\n",
      "🧪 Function tests:\n",
      "   Versioned URL test: True (should be True)\n",
      "   Unversioned URL test: False (should be False)\n",
      "   Strip version test: /orgs/CIEL/sources/CIEL/concepts/1015/\n",
      "   Reference type test: concepts\n",
      "   Normalize test: /orgs/ciel/sources/ciel/concepts/1015/\n"
     ]
    }
   ],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def is_versioned_url(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if URL contains a version number after concepts, sources, or mappings.\n",
    "    \n",
    "    Examples of versioned URLs:\n",
    "    - /orgs/CIEL/sources/CIEL/concepts/1015/5282451/\n",
    "    - /users/jamlung/sources/openmrs-demo-source/mappings/76/6495007/\n",
    "    \"\"\"\n",
    "    return bool(re.search(r'/(concepts|sources|mappings)/[^/]+/\\d+/?$', url))\n",
    "\n",
    "\n",
    "def strip_version_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove version number from concepts, sources, or mappings URLs.\n",
    "    \"\"\"\n",
    "    return re.sub(r'/(concepts|sources|mappings)/([^/]+)/\\d+/?$', r'/\\1/\\2/', url)\n",
    "\n",
    "\n",
    "def get_reference_type(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if reference is to concepts or mappings.\n",
    "    \"\"\"\n",
    "    if '/concepts/' in url:\n",
    "        return 'concepts'\n",
    "    elif '/mappings/' in url:\n",
    "        return 'mappings'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "def extract_cascade_from_reference(ref_data: Dict) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Extract cascade settings from original reference data.\n",
    "    \"\"\"\n",
    "    # Look for cascade in various possible locations\n",
    "    cascade_fields = ['cascade', '__cascade', 'cascadeOptions']\n",
    "    \n",
    "    for field in cascade_fields:\n",
    "        if field in ref_data and ref_data[field]:\n",
    "            return ref_data[field]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_expression(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize expression for duplicate detection.\n",
    "    Ensures consistent trailing slashes and case.\n",
    "    \"\"\"\n",
    "    if not expression:\n",
    "        return \"\"\n",
    "    \n",
    "    # Ensure trailing slash for consistency\n",
    "    if not expression.endswith('/'):\n",
    "        expression += '/'\n",
    "    \n",
    "    return expression.lower()\n",
    "\n",
    "print(\"🔧 Utility functions defined successfully!\")\n",
    "\n",
    "# Test the functions with examples\n",
    "test_versioned = \"/orgs/CIEL/sources/CIEL/concepts/1015/5282451/\"\n",
    "test_unversioned = \"/orgs/CIEL/sources/CIEL/concepts/1015/\"\n",
    "\n",
    "print(f\"\\n🧪 Function tests:\")\n",
    "print(f\"   Versioned URL test: {is_versioned_url(test_versioned)} (should be True)\")\n",
    "print(f\"   Unversioned URL test: {is_versioned_url(test_unversioned)} (should be False)\")\n",
    "print(f\"   Strip version test: {strip_version_from_url(test_versioned)}\")\n",
    "print(f\"   Reference type test: {get_reference_type(test_versioned)}\")\n",
    "print(f\"   Normalize test: {normalize_expression(test_unversioned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define File I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 File I/O functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# FILE I/O FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_collection_export(file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load collection data from OCL version export JSON file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Export file not found: {file_path}\")\n",
    "    \n",
    "    print(f\"📥 Loading collection export from: {file_path}\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"✅ Export file loaded successfully\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_references_from_export(export_data: Dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract references from collection export data.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"🔍 Extracting references from export data...\")\n",
    "    \n",
    "    references = export_data.get('references', [])\n",
    "    \n",
    "    if not references:\n",
    "        print(\"   ⚠️ No references found in export data\")\n",
    "        return []\n",
    "    \n",
    "    if not isinstance(references, list):\n",
    "        print(\"   ❌ References field is not a list\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"   ✅ Found {len(references)} references\")\n",
    "    \n",
    "    # Optional: Show a sample reference structure for debugging\n",
    "    if references:\n",
    "        sample_ref = references[0]\n",
    "        print(f\"   📋 Sample reference keys: {list(sample_ref.keys())}\")\n",
    "        if 'expression' in sample_ref:\n",
    "            print(f\"   📋 Sample expression: {sample_ref['expression']}\")\n",
    "    \n",
    "    return references\n",
    "\n",
    "\n",
    "def save_jsonl(data: List[Dict], filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save data as JSONL (JSON Lines) format compatible with OCL bulk import.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(filename) if os.path.dirname(filename) else '.', exist_ok=True)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for item in data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        print(f\"💾 Saved {len(data)} items to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"❌ Error saving {filename}: {e}\")\n",
    "\n",
    "print(\"📁 File I/O functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Reference Processing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Processing classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# REFERENCE PROCESSING CLASSES\n",
    "# =============================================================================\n",
    "\n",
    "class ReferenceProcessor:\n",
    "    \"\"\"Handles the processing and transformation of references.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.stats = {\n",
    "            'total_references': 0,\n",
    "            'versioned_references': 0,\n",
    "            'unversioned_references': 0,\n",
    "            'concept_references': 0,\n",
    "            'mapping_references': 0,\n",
    "            'other_references': 0,\n",
    "            'cascade_preserved': 0,\n",
    "            'cascade_preset': 0,\n",
    "            'duplicates_found': 0,\n",
    "            'duplicates_skipped': 0,\n",
    "            'references_to_modernize': 0,\n",
    "            'references_unchanged': 0\n",
    "        }\n",
    "        self.seen_expressions: Set[str] = set()\n",
    "        self.duplicate_expressions: List[str] = []\n",
    "        self.export_data = None\n",
    "    \n",
    "    def analyze_references(self, references: List[Dict]) -> None:\n",
    "        \"\"\"Analyze reference patterns and update statistics.\"\"\"\n",
    "        print(\"📊 Analyzing references...\")\n",
    "        \n",
    "        self.stats['total_references'] = len(references)\n",
    "        \n",
    "        for i, ref in enumerate(references):\n",
    "            # Get the expression/URL from reference\n",
    "            expression = self._extract_expression(ref)\n",
    "            if not expression:\n",
    "                continue\n",
    "            \n",
    "            # Check if versioned\n",
    "            if is_versioned_url(expression):\n",
    "                self.stats['versioned_references'] += 1\n",
    "            else:\n",
    "                self.stats['unversioned_references'] += 1\n",
    "            \n",
    "            # Check reference type\n",
    "            ref_type = get_reference_type(expression)\n",
    "            if ref_type == 'concepts':\n",
    "                self.stats['concept_references'] += 1\n",
    "            elif ref_type == 'mappings':\n",
    "                self.stats['mapping_references'] += 1\n",
    "            else:\n",
    "                self.stats['other_references'] += 1\n",
    "        \n",
    "        print(\"✅ Reference analysis complete!\")\n",
    "    \n",
    "    def _extract_expression(self, ref: Dict) -> str:\n",
    "        \"\"\"Extract the main expression/URL from a reference.\"\"\"\n",
    "        # Try common field names for the reference URL\n",
    "        possible_fields = ['expression', 'url', 'uri', 'reference_url']\n",
    "        \n",
    "        for field in possible_fields:\n",
    "            if field in ref and ref[field]:\n",
    "                return ref[field]\n",
    "        \n",
    "        # If it's in a nested structure\n",
    "        if 'data' in ref and 'expressions' in ref['data']:\n",
    "            expressions = ref['data']['expressions']\n",
    "            if expressions and len(expressions) > 0:\n",
    "                return expressions[0]\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    def _get_collection_url(self, ref: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Extract collection URL from export data.\n",
    "        \n",
    "        In OCL exports, the collection URL is available at:\n",
    "        - export_data['url'] = \"/users/jamlung/collections/squad-test-not-validation/\"\n",
    "        - export_data['collection']['url'] = \"/users/jamlung/collections/squad-test-not-validation/\"\n",
    "        \"\"\"\n",
    "        if not self.export_data:\n",
    "            print(\"   ⚠️ Export data not available for collection URL extraction\")\n",
    "            return \"/collections/unknown/\"\n",
    "            \n",
    "        # Try main URL field first (this is the collection URL)\n",
    "        if 'url' in self.export_data:\n",
    "            collection_url = self.export_data['url']\n",
    "            # Ensure it ends with /\n",
    "            return collection_url if collection_url.endswith('/') else collection_url + '/'\n",
    "        \n",
    "        # Try nested collection.url field\n",
    "        if 'collection' in self.export_data and 'url' in self.export_data['collection']:\n",
    "            collection_url = self.export_data['collection']['url']\n",
    "            # Ensure it ends with /\n",
    "            return collection_url if collection_url.endswith('/') else collection_url + '/'\n",
    "        \n",
    "        print(\"   ⚠️ Could not determine collection URL from export data\")\n",
    "        return \"/collections/unknown/\"\n",
    "    \n",
    "    def _is_duplicate_expression(self, expression: str) -> bool:\n",
    "        \"\"\"Check if expression is a duplicate and track it.\"\"\"\n",
    "        normalized = normalize_expression(expression)\n",
    "        \n",
    "        if normalized in self.seen_expressions:\n",
    "            self.stats['duplicates_found'] += 1\n",
    "            if self.config.REPORT_DUPLICATES:\n",
    "                self.duplicate_expressions.append(expression)\n",
    "            return True\n",
    "        \n",
    "        self.seen_expressions.add(normalized)\n",
    "        return False\n",
    "    \n",
    "    def process_references(self, references: List[Dict], export_data: Dict) -> Tuple[List[Dict], List[Dict]]:\n",
    "        \"\"\"\n",
    "        Process references to create unversioned equivalents and deletion commands.\n",
    "        ONLY processes versioned references for modernization.\n",
    "        \"\"\"\n",
    "        self.export_data = export_data\n",
    "        self.analyze_references(references)\n",
    "        \n",
    "        processed_references = []\n",
    "        references_to_delete = []\n",
    "        \n",
    "        print(f\"\\n🔄 Processing {len(references)} references...\")\n",
    "        print(f\"   🎯 Strategy: Only modernize versioned references\")\n",
    "        print(f\"   🚫 Duplicate handling: {'Skip' if self.config.SKIP_DUPLICATES else 'Allow'}\")\n",
    "        \n",
    "        collection_url = self._get_collection_url({})\n",
    "        \n",
    "        for i, ref in enumerate(references, 1):\n",
    "            expression = self._extract_expression(ref)\n",
    "            if not expression:\n",
    "                print(f\"   ⚠️ Warning: Could not extract expression from reference {i}\")\n",
    "                continue\n",
    "            \n",
    "            # ✨ KEY CHANGE: Only process versioned references\n",
    "            if not is_versioned_url(expression):\n",
    "                self.stats['references_unchanged'] += 1\n",
    "                continue  # Skip unversioned references\n",
    "            \n",
    "            self.stats['references_to_modernize'] += 1\n",
    "            \n",
    "            # Create unversioned equivalent\n",
    "            unversioned_expression = strip_version_from_url(expression)\n",
    "            \n",
    "            # Check for duplicates\n",
    "            if self.config.SKIP_DUPLICATES and self._is_duplicate_expression(unversioned_expression):\n",
    "                self.stats['duplicates_skipped'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Determine cascade settings\n",
    "            cascade_settings = None\n",
    "            if self.config.PRESERVE_ORIGINAL_CASCADE:\n",
    "                original_cascade = extract_cascade_from_reference(ref)\n",
    "                if original_cascade:\n",
    "                    cascade_settings = original_cascade\n",
    "                    self.stats['cascade_preserved'] += 1\n",
    "            \n",
    "            if cascade_settings is None:\n",
    "                cascade_settings = self.config.get_cascade_settings()\n",
    "                self.stats['cascade_preset'] += 1\n",
    "            \n",
    "            # Create unversioned reference\n",
    "            new_ref = {\n",
    "                \"type\": \"Reference\",\n",
    "                \"collection_url\": collection_url,\n",
    "                \"data\": {\n",
    "                    \"expressions\": [unversioned_expression]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add cascade if specified (only for concept references)\n",
    "            if cascade_settings and get_reference_type(unversioned_expression) == 'concepts':\n",
    "                new_ref[\"__cascade\"] = cascade_settings\n",
    "            \n",
    "            processed_references.append(new_ref)\n",
    "            \n",
    "            # Create deletion command for the versioned reference\n",
    "            delete_ref = {\n",
    "                \"type\": \"Reference\",\n",
    "                \"collection_url\": collection_url,\n",
    "                \"data\": {\n",
    "                    \"expressions\": [expression]  # Keep original versioned URL\n",
    "                },\n",
    "                \"__action\": \"DELETE\"\n",
    "                # Note: Intentionally NOT including cascade for deletes\n",
    "            }\n",
    "            references_to_delete.append(delete_ref)\n",
    "        \n",
    "        print(f\"\\n✅ Processing complete!\")\n",
    "        print(f\"   📤 Unversioned references to add: {len(processed_references)}\")\n",
    "        print(f\"   🗑️ Versioned references to delete: {len(references_to_delete)}\")\n",
    "        print(f\"   ⚡ References left unchanged: {self.stats['references_unchanged']}\")\n",
    "        if self.stats['duplicates_skipped'] > 0:\n",
    "            print(f\"   🚫 Duplicates skipped: {self.stats['duplicates_skipped']}\")\n",
    "        \n",
    "        return processed_references, references_to_delete\n",
    "\n",
    "\n",
    "class ReportGenerator:\n",
    "    \"\"\"Generates detailed reports on the migration process.\"\"\"\n",
    "    \n",
    "    def __init__(self, processor: ReferenceProcessor):\n",
    "        self.processor = processor\n",
    "        self.stats = processor.stats\n",
    "    \n",
    "    def print_summary(self) -> None:\n",
    "        \"\"\"Print a summary to console.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"📊 MODERNIZATION SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"📁 Total references: {self.stats['total_references']}\")\n",
    "        print(f\"   🧬 Concepts: {self.stats['concept_references']}\")\n",
    "        print(f\"   🔗 Mappings: {self.stats['mapping_references']}\")\n",
    "        print(f\"   ❓ Other: {self.stats['other_references']}\")\n",
    "        print()\n",
    "        print(f\"🏷️ Reference Versions:\")\n",
    "        print(f\"   📌 Versioned (to modernize): {self.stats['versioned_references']}\")\n",
    "        print(f\"   📄 Already unversioned: {self.stats['unversioned_references']}\")\n",
    "        print()\n",
    "        print(f\"⚙️ Cascade Handling:\")\n",
    "        print(f\"   💾 Original preserved: {self.stats['cascade_preserved']}\")\n",
    "        print(f\"   🔧 Preset applied: {self.stats['cascade_preset']}\")\n",
    "        print()\n",
    "        print(f\"🚫 Duplicate Handling:\")\n",
    "        print(f\"   🔍 Duplicates found: {self.stats['duplicates_found']}\")\n",
    "        print(f\"   ⏭️ Duplicates skipped: {self.stats['duplicates_skipped']}\")\n",
    "        print()\n",
    "        print(f\"📈 Migration Impact:\")\n",
    "        print(f\"   🗑️ References to remove: {self.stats['references_to_modernize']}\")\n",
    "        print(f\"   ➕ References to add: {len(self.processor.seen_expressions) - self.stats['duplicates_skipped']}\")\n",
    "        print(f\"   ⚡ References unchanged: {self.stats['references_unchanged']}\")\n",
    "        print(f\"   📊 Net change: +{len(self.processor.seen_expressions) - self.stats['duplicates_skipped'] - self.stats['references_to_modernize']}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Show duplicate examples if any\n",
    "        if self.processor.duplicate_expressions:\n",
    "            print(f\"\\n🚫 Duplicate expressions found (showing first 5):\")\n",
    "            for i, expr in enumerate(self.processor.duplicate_expressions[:5]):\n",
    "                print(f\"   {i+1}. {expr}\")\n",
    "            if len(self.processor.duplicate_expressions) > 5:\n",
    "                print(f\"   ... and {len(self.processor.duplicate_expressions) - 5} more\")\n",
    "    \n",
    "    def generate_report(self, output_file: str) -> None:\n",
    "        \"\"\"Generate a detailed migration report.\"\"\"\n",
    "        report_lines = [\n",
    "            \"OCL Reference Modernizer - Migration Report\",\n",
    "            \"=\" * 50,\n",
    "            f\"Generated: {datetime.now().isoformat()}\",\n",
    "            f\"GitHub Issue: https://github.com/OpenConceptLab/ocl_issues/issues/2212\",\n",
    "            f\"Cascade Preset: {self.processor.config.CASCADE_PRESET}\",\n",
    "            \"\",\n",
    "            \"REFERENCE ANALYSIS\",\n",
    "            \"-\" * 20,\n",
    "            f\"Total references found: {self.stats['total_references']}\",\n",
    "            f\"Versioned references (to modernize): {self.stats['versioned_references']}\",\n",
    "            f\"Already unversioned (unchanged): {self.stats['unversioned_references']}\",\n",
    "            f\"References processed: {self.stats['references_to_modernize']}\",\n",
    "            \"\",\n",
    "            \"REFERENCE TYPES\",\n",
    "            \"-\" * 15,\n",
    "            f\"Concept references: {self.stats['concept_references']}\",\n",
    "            f\"Mapping references: {self.stats['mapping_references']}\",\n",
    "            f\"Other references: {self.stats['other_references']}\",\n",
    "            \"\",\n",
    "            \"CASCADE HANDLING\",\n",
    "            \"-\" * 15,\n",
    "            f\"Original cascade preserved: {self.stats['cascade_preserved']}\",\n",
    "            f\"Preset cascade applied: {self.stats['cascade_preset']}\",\n",
    "            \"\",\n",
    "            \"DUPLICATE HANDLING\",\n",
    "            \"-\" * 17,\n",
    "            f\"Duplicates found: {self.stats['duplicates_found']}\",\n",
    "            f\"Duplicates skipped: {self.stats['duplicates_skipped']}\",\n",
    "            \"\",\n",
    "            \"MIGRATION SUMMARY\",\n",
    "            \"-\" * 17,\n",
    "            f\"References to be deleted: {self.stats['references_to_modernize']}\",\n",
    "            f\"New unversioned references: {len(self.processor.seen_expressions) - self.stats['duplicates_skipped']}\",\n",
    "            f\"References left unchanged: {self.stats['references_unchanged']}\",\n",
    "            f\"Net change in references: {len(self.processor.seen_expressions) - self.stats['duplicates_skipped'] - self.stats['references_to_modernize']}\",\n",
    "            \"\",\n",
    "            \"NEXT STEPS\",\n",
    "            \"-\" * 10,\n",
    "            \"1. Review generated JSONL files\",\n",
    "            \"2. Test import on a backup/test collection first\",\n",
    "            \"3. Use OCL's Bulk Import Interface\",\n",
    "            \"4. Import deletion file FIRST to remove versioned references\",\n",
    "            \"5. Import unversioned references file SECOND\",\n",
    "            \"6. Verify collection state and expansions\"\n",
    "        ]\n",
    "        \n",
    "        # Add duplicate details if any\n",
    "        if self.processor.duplicate_expressions:\n",
    "            report_lines.extend([\n",
    "                \"\",\n",
    "                \"DUPLICATE EXPRESSIONS FOUND\",\n",
    "                \"-\" * 27\n",
    "            ])\n",
    "            for expr in self.processor.duplicate_expressions[:20]:\n",
    "                report_lines.append(f\"- {expr}\")\n",
    "            if len(self.processor.duplicate_expressions) > 20:\n",
    "                report_lines.append(f\"... and {len(self.processor.duplicate_expressions) - 20} more\")\n",
    "        \n",
    "        try:\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write('\\n'.join(report_lines))\n",
    "            print(f\"📄 Migration report saved to: {output_file}\")\n",
    "        except IOError as e:\n",
    "            print(f\"❌ Error saving report: {e}\")\n",
    "\n",
    "print(\"🔧 Processing classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load and Validate Input File\n",
    "\n",
    "**📁 Let's load your OCL export file and see what we're working with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Checking input file: input-example-jamlung/export.json\n",
      "📥 Loading collection export from: input-example-jamlung/export.json\n",
      "✅ Export file loaded successfully\n",
      "📊 File size: 180,743 bytes (0.2 MB)\n",
      "🔑 Top-level keys in export: ['type', 'uuid', 'id', 'short_code', 'name', 'full_name', 'description', 'collection_type', 'custom_validation_schema', 'public_access', 'default_locale', 'supported_locales', 'website', 'url', 'owner', 'owner_type', 'owner_url', 'version_url', 'previous_version_url', 'created_on', 'updated_on', 'created_by', 'updated_by', 'extras', 'external_id', 'version', 'concepts_url', 'mappings_url', 'expansions_url', 'is_processing', 'released', 'retired', 'canonical_url', 'identifier', 'publisher', 'contact', 'jurisdiction', 'purpose', 'copyright', 'meta', 'immutable', 'revision_date', 'text', 'experimental', 'locked_date', 'autoexpand', 'expansion_url', 'checksums', 'collection', 'concepts', 'references', 'mappings', 'export_time']\n",
      "🏠 Collection URL: /users/jamlung/collections/facility-test/\n",
      "📛 Collection name: facility-test\n",
      "\n",
      "✅ Export file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check if input file exists and load it\n",
    "print(f\"📁 Checking input file: {config.INPUT_FILE}\")\n",
    "\n",
    "if not os.path.exists(config.INPUT_FILE):\n",
    "    print(f\"❌ File not found: {config.INPUT_FILE}\")\n",
    "    print(\"\\n📋 Please:\")\n",
    "    print(\"   1. Export your OCL collection to JSON format\")\n",
    "    print(\"   2. Update the INPUT_FILE path in the Configuration cell\")\n",
    "    print(\"   3. Re-run this cell\")\n",
    "    export_data = None\n",
    "else:\n",
    "    try:\n",
    "        # Load the export file\n",
    "        export_data = load_collection_export(config.INPUT_FILE)\n",
    "        \n",
    "        # Show basic file info\n",
    "        file_size = os.path.getsize(config.INPUT_FILE)\n",
    "        print(f\"📊 File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n",
    "        \n",
    "        # Show top-level keys in export\n",
    "        if isinstance(export_data, dict):\n",
    "            print(f\"🔑 Top-level keys in export: {list(export_data.keys())}\")\n",
    "        \n",
    "        # Show collection info\n",
    "        if 'url' in export_data:\n",
    "            print(f\"🏠 Collection URL: {export_data['url']}\")\n",
    "        if 'name' in export_data:\n",
    "            print(f\"📛 Collection name: {export_data['name']}\")\n",
    "        \n",
    "        print(\"\\n✅ Export file loaded successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading file: {e}\")\n",
    "        export_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extract References from Export\n",
    "\n",
    "**📤 Now let's extract the references from your export file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Extracting references from export data...\n",
      "   ✅ Found 21 references\n",
      "   📋 Sample reference keys: ['expression', 'reference_type', 'id', 'last_resolved_at', 'uri', 'uuid', 'include', 'type', 'code', 'resource_version', 'namespace', 'system', 'version', 'valueset', 'cascade', 'filter', 'display', 'created_at', 'updated_at', 'concepts', 'mappings', 'translation', 'transform']\n",
      "   📋 Sample expression: /users/jamlung/sources/zim_demo/concepts/12/\n",
      "\n",
      "🎯 Success! Found 21 references to analyze.\n",
      "\n",
      "📋 Sample reference structure:\n",
      "   expression: /users/jamlung/sources/zim_demo/concepts/12/\n",
      "   reference_type: concepts\n",
      "   id: 11654253\n",
      "   last_resolved_at: 2025-08-20T14:50:33.697777Z\n",
      "   uri: /users/jamlung/collections/facility-test/script-te...\n",
      "   uuid: 11654253\n",
      "   include: True\n",
      "   type: CollectionReference\n",
      "   code: 12\n",
      "   resource_version: None\n",
      "   namespace: None\n",
      "   system: /users/jamlung/sources/zim_demo/\n",
      "   version: None\n",
      "   valueset: None\n",
      "   cascade: {'method': 'sourcetoconcepts', 'map_types': 'Q-AND-A,CONCEPT-SET', 'cascade_levels': '*', 'return_map_types': '*'}\n",
      "   filter: None\n",
      "   display: None\n",
      "   created_at: 2025-08-20T14:50:33.700951Z\n",
      "   updated_at: 2025-08-20T14:50:33.700969Z\n",
      "   concepts: 11\n",
      "   mappings: 62\n",
      "   translation: Include latest concept \"12\" from jamlung/zim_demo ...\n",
      "   transform: \n",
      "\n",
      "🔍 Quick analysis:\n",
      "   📌 Versioned references: 18\n",
      "   📄 Unversioned references: 3\n"
     ]
    }
   ],
   "source": [
    "if export_data is None:\n",
    "    print(\"❌ No export data available. Please fix the input file issue above.\")\n",
    "    references = []\n",
    "else:\n",
    "    try:\n",
    "        # Extract references from the export\n",
    "        references = extract_references_from_export(export_data)\n",
    "        \n",
    "        if not references:\n",
    "            print(\"⚠️ No references found in export file.\")\n",
    "            print(\"\\n📋 Export structure:\")\n",
    "            if isinstance(export_data, dict):\n",
    "                for key in export_data.keys():\n",
    "                    value = export_data[key]\n",
    "                    if isinstance(value, list):\n",
    "                        print(f\"   📋 {key}: {len(value)} items\")\n",
    "                    else:\n",
    "                        print(f\"   📁 {key}: {type(value).__name__}\")\n",
    "        else:\n",
    "            print(f\"\\n🎯 Success! Found {len(references)} references to analyze.\")\n",
    "            \n",
    "            # Show sample reference structure\n",
    "            if references:\n",
    "                print(\"\\n📋 Sample reference structure:\")\n",
    "                sample_ref = references[0]\n",
    "                for key, value in sample_ref.items():\n",
    "                    if isinstance(value, str) and len(value) > 50:\n",
    "                        print(f\"   {key}: {value[:50]}...\")\n",
    "                    else:\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                        \n",
    "                # Quick analysis\n",
    "                versioned_count = sum(1 for ref in references if 'expression' in ref and is_versioned_url(ref['expression']))\n",
    "                print(f\"\\n🔍 Quick analysis:\")\n",
    "                print(f\"   📌 Versioned references: {versioned_count}\")\n",
    "                print(f\"   📄 Unversioned references: {len(references) - versioned_count}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error extracting references: {e}\")\n",
    "        references = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Process References\n",
    "\n",
    "**⚙️ Now let's process the references and generate the modernized versions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Analyzing references...\n",
      "✅ Reference analysis complete!\n",
      "\n",
      "🔄 Processing 21 references...\n",
      "   🎯 Strategy: Only modernize versioned references\n",
      "   🚫 Duplicate handling: Skip\n",
      "\n",
      "✅ Processing complete!\n",
      "   📤 Unversioned references to add: 18\n",
      "   🗑️ Versioned references to delete: 18\n",
      "   ⚡ References left unchanged: 3\n",
      "\n",
      "============================================================\n",
      "📊 MODERNIZATION SUMMARY\n",
      "============================================================\n",
      "📁 Total references: 21\n",
      "   🧬 Concepts: 6\n",
      "   🔗 Mappings: 15\n",
      "   ❓ Other: 0\n",
      "\n",
      "🏷️ Reference Versions:\n",
      "   📌 Versioned (to modernize): 18\n",
      "   📄 Already unversioned: 3\n",
      "\n",
      "⚙️ Cascade Handling:\n",
      "   💾 Original preserved: 0\n",
      "   🔧 Preset applied: 18\n",
      "\n",
      "🚫 Duplicate Handling:\n",
      "   🔍 Duplicates found: 0\n",
      "   ⏭️ Duplicates skipped: 0\n",
      "\n",
      "📈 Migration Impact:\n",
      "   🗑️ References to remove: 18\n",
      "   ➕ References to add: 18\n",
      "   ⚡ References unchanged: 3\n",
      "   📊 Net change: +0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if not references:\n",
    "    print(\"❌ No references to process. Please check the steps above.\")\n",
    "    processor = None\n",
    "    processed_references = []\n",
    "    references_to_delete = []\n",
    "else:\n",
    "    try:\n",
    "        # Initialize the processor\n",
    "        processor = ReferenceProcessor(config)\n",
    "        \n",
    "        # Process the references\n",
    "        processed_references, references_to_delete = processor.process_references(references, export_data)\n",
    "        \n",
    "        # Show detailed results\n",
    "        report_generator = ReportGenerator(processor)\n",
    "        report_generator.print_summary()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing references: {e}\")\n",
    "        processor = None\n",
    "        processed_references = []\n",
    "        references_to_delete = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Output Files\n",
    "\n",
    "**💾 Let's save the results to files for OCL bulk import:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving output files...\n",
      "📂 Output directory: output\n",
      "💾 Saved 18 items to output\\unversioned_references_20250820_105615.json\n",
      "💾 Saved 18 items to output\\references_to_delete_20250820_105615.json\n",
      "📄 Migration report saved to: output\\migration_report_20250820_105615.txt\n",
      "\n",
      "✅ All files saved successfully!\n",
      "\n",
      "📁 Generated files:\n",
      "   📤 Unversioned references: output\\unversioned_references_20250820_105615.json\n",
      "   🗑️ References to delete: output\\references_to_delete_20250820_105615.json\n",
      "   📄 Migration report: output\\migration_report_20250820_105615.txt\n"
     ]
    }
   ],
   "source": [
    "if not processed_references and not references_to_delete:\n",
    "    print(\"❌ No processed references to save. Please check the processing step above.\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"💾 Saving output files...\")\n",
    "        \n",
    "        # Create output directory\n",
    "        output_dir = config.OUTPUT_DIR\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"📂 Output directory: {output_dir}\")\n",
    "        \n",
    "        # Generate file paths\n",
    "        unversioned_path = os.path.join(output_dir, config.UNVERSIONED_FILE)\n",
    "        delete_path = os.path.join(output_dir, config.DELETE_FILE)\n",
    "        report_path = os.path.join(output_dir, config.REPORT_FILE)\n",
    "        \n",
    "        # Save the files\n",
    "        if processed_references:\n",
    "            save_jsonl(processed_references, unversioned_path)\n",
    "        else:\n",
    "            print(\"   ℹ️ No unversioned references to save (no versioned references found)\")\n",
    "            \n",
    "        if references_to_delete:\n",
    "            save_jsonl(references_to_delete, delete_path)\n",
    "        else:\n",
    "            print(\"   ℹ️ No references to delete (no versioned references found)\")\n",
    "        \n",
    "        # Generate detailed report\n",
    "        if processor:\n",
    "            report_generator = ReportGenerator(processor)\n",
    "            report_generator.generate_report(report_path)\n",
    "        \n",
    "        print(\"\\n✅ All files saved successfully!\")\n",
    "        print(f\"\\n📁 Generated files:\")\n",
    "        if processed_references:\n",
    "            print(f\"   📤 Unversioned references: {unversioned_path}\")\n",
    "        if references_to_delete:\n",
    "            print(f\"   🗑️ References to delete: {delete_path}\")\n",
    "        print(f\"   📄 Migration report: {report_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Preview Generated Files\n",
    "\n",
    "**👀 Let's take a look at what we generated:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👁️ Previewing generated files...\n",
      "\n",
      "📄 Preview of unversioned_references_20250820_105615.json (first 2 lines):\n",
      "--------------------------------------------------\n",
      "Line 1:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/314250/\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "Line 2:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/312829/\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "📄 Preview of references_to_delete_20250820_105615.json (first 2 lines):\n",
      "--------------------------------------------------\n",
      "Line 1:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/314250/5406810/\"\n",
      "    ]\n",
      "  },\n",
      "  \"__action\": \"DELETE\"\n",
      "}\n",
      "\n",
      "Line 2:\n",
      "{\n",
      "  \"type\": \"Reference\",\n",
      "  \"collection_url\": \"/users/jamlung/collections/facility-test/\",\n",
      "  \"data\": {\n",
      "    \"expressions\": [\n",
      "      \"/orgs/CIEL/sources/CIEL/mappings/312829/5386191/\"\n",
      "    ]\n",
      "  },\n",
      "  \"__action\": \"DELETE\"\n",
      "}\n",
      "\n",
      "📊 unversioned_references_20250820_105615.json: 18 lines, 3,346 bytes\n",
      "📊 references_to_delete_20250820_105615.json: 18 lines, 3,370 bytes\n"
     ]
    }
   ],
   "source": [
    "def display_file_preview(filename: str, num_lines: int = 3) -> None:\n",
    "    \"\"\"Display preview of a JSONL file.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"\\n📄 Preview of {os.path.basename(filename)} (first {num_lines} lines):\")\n",
    "            print(\"-\" * 50)\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                for i, line in enumerate(f):\n",
    "                    if i < num_lines:\n",
    "                        try:\n",
    "                            data = json.loads(line.strip())\n",
    "                            print(f\"Line {i+1}:\")\n",
    "                            print(json.dumps(data, indent=2))\n",
    "                            print()\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(f\"Line {i+1}: {line.strip()}\")\n",
    "                    else:\n",
    "                        break\n",
    "        else:\n",
    "            print(f\"❌ File not found: {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"❌ Error reading {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Preview the generated files\n",
    "if config.OUTPUT_DIR:\n",
    "    unversioned_path = os.path.join(config.OUTPUT_DIR, config.UNVERSIONED_FILE)\n",
    "    delete_path = os.path.join(config.OUTPUT_DIR, config.DELETE_FILE)\n",
    "    \n",
    "    print(\"👁️ Previewing generated files...\")\n",
    "    \n",
    "    if os.path.exists(unversioned_path):\n",
    "        display_file_preview(unversioned_path, 2)\n",
    "    else:\n",
    "        print(f\"\\nℹ️ {os.path.basename(unversioned_path)} not created (no versioned references to modernize)\")\n",
    "        \n",
    "    if os.path.exists(delete_path):\n",
    "        display_file_preview(delete_path, 2)\n",
    "    else:\n",
    "        print(f\"\\nℹ️ {os.path.basename(delete_path)} not created (no versioned references to delete)\")\n",
    "    \n",
    "    # Show file sizes\n",
    "    for filepath in [unversioned_path, delete_path]:\n",
    "        if os.path.exists(filepath):\n",
    "            size = os.path.getsize(filepath)\n",
    "            with open(filepath, 'r') as f:\n",
    "                lines = sum(1 for _ in f)\n",
    "            print(f\"📊 {os.path.basename(filepath)}: {lines} lines, {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Validation & Next Steps\n",
    "\n",
    "**✅ Let's validate our results and plan next steps:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VALIDATION CHECKLIST\n",
      "========================================\n",
      "✅ 📊 References found\n",
      "✅ 🏷️ Versioned refs identified\n",
      "✅ 🔧 Processing completed\n",
      "✅ 🚫 Duplicate handling configured\n",
      "✅ ⚙️ Cascade handling configured\n",
      "\n",
      "📋 STATISTICS SUMMARY:\n",
      "   📁 Total references: 21\n",
      "   🧬 Concept references: 6\n",
      "   🔗 Mapping references: 15\n",
      "   📌 Versioned (to modernize): 18\n",
      "   📄 Already unversioned: 3\n",
      "   🚫 Duplicates handled: 0 found, 0 skipped\n",
      "\n",
      "🎯 EXPECTED RESULTS AFTER MIGRATION:\n",
      "   🗑️ References to be deleted: 18\n",
      "   ➕ References to be added: 18\n",
      "   ⚡ References left unchanged: 3\n",
      "   📊 Net change: 0\n",
      "\n",
      "========================================\n",
      "🚀 NEXT STEPS\n",
      "========================================\n",
      "1. 📋 Review the migration report and file previews above\n",
      "2. 💾 Backup your OCL collection (create a version)\n",
      "3. 🧪 Test on a backup/test collection first (recommended)\n",
      "4. 🌐 Use OCL's Bulk Import Interface:\n",
      "   a. Import the DELETE file FIRST\n",
      "   b. Then import the unversioned references file\n",
      "5. ✅ Verify collection state and functionality\n",
      "6. 📊 Check collection expansion results\n",
      "\n",
      "⚠️ IMPORTANT REMINDERS:\n",
      "   • Always backup before applying changes\n",
      "   • Test on a small collection first\n",
      "   • Apply deletions BEFORE additions\n",
      "   • Validate results thoroughly\n",
      "\n",
      "📁 Your files are ready in: output/\n",
      "   🕐 Generated at: 20250820_105615\n",
      "   🎛️ Using cascade preset: OPENMRS_WITHOUT_TRANSFORM\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 VALIDATION CHECKLIST\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if we have valid results\n",
    "if processor and hasattr(processor, 'stats'):\n",
    "    stats = processor.stats\n",
    "    \n",
    "    # Validation checks\n",
    "    checks = [\n",
    "        (\"📊 References found\", stats['total_references'] > 0),\n",
    "        (\"🏷️ Versioned refs identified\", stats['versioned_references'] >= 0),\n",
    "        (\"🔧 Processing completed\", True),  # If we got here, processing completed\n",
    "        (\"🚫 Duplicate handling configured\", config.SKIP_DUPLICATES),\n",
    "        (\"⚙️ Cascade handling configured\", True),  # Always true if we got this far\n",
    "    ]\n",
    "    \n",
    "    for check_name, passed in checks:\n",
    "        status = \"✅\" if passed else \"❌\"\n",
    "        print(f\"{status} {check_name}\")\n",
    "    \n",
    "    print(\"\\n📋 STATISTICS SUMMARY:\")\n",
    "    print(f\"   📁 Total references: {stats['total_references']}\")\n",
    "    print(f\"   🧬 Concept references: {stats['concept_references']}\")\n",
    "    print(f\"   🔗 Mapping references: {stats['mapping_references']}\")\n",
    "    print(f\"   📌 Versioned (to modernize): {stats['versioned_references']}\")\n",
    "    print(f\"   📄 Already unversioned: {stats['unversioned_references']}\")\n",
    "    print(f\"   🚫 Duplicates handled: {stats['duplicates_found']} found, {stats['duplicates_skipped']} skipped\")\n",
    "    \n",
    "    print(\"\\n🎯 EXPECTED RESULTS AFTER MIGRATION:\")\n",
    "    if stats['versioned_references'] > 0:\n",
    "        print(f\"   🗑️ References to be deleted: {stats['references_to_modernize']}\")\n",
    "        print(f\"   ➕ References to be added: {len(processed_references)}\")\n",
    "        print(f\"   ⚡ References left unchanged: {stats['references_unchanged']}\")\n",
    "        print(f\"   📊 Net change: {len(processed_references) - stats['references_to_modernize']}\")\n",
    "    else:\n",
    "        print(f\"   ℹ️ No versioned references found - collection is already modernized!\")\n",
    "        print(f\"   📊 All {stats['total_references']} references are already unversioned\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No valid processing results to validate.\")\n",
    "    print(\"   Please check the previous steps for errors.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"🚀 NEXT STEPS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if processor and processor.stats['versioned_references'] > 0:\n",
    "    print(\"1. 📋 Review the migration report and file previews above\")\n",
    "    print(\"2. 💾 Backup your OCL collection (create a version)\")\n",
    "    print(\"3. 🧪 Test on a backup/test collection first (recommended)\")\n",
    "    print(\"4. 🌐 Use OCL's Bulk Import Interface:\")\n",
    "    print(\"   a. Import the DELETE file FIRST\")\n",
    "    print(\"   b. Then import the unversioned references file\")\n",
    "    print(\"5. ✅ Verify collection state and functionality\")\n",
    "    print(\"6. 📊 Check collection expansion results\")\n",
    "else:\n",
    "    print(\"🎉 Great news! Your collection is already modernized.\")\n",
    "    print(\"   ✅ All references are already unversioned\")\n",
    "    print(\"   📊 No migration needed\")\n",
    "\n",
    "print(\"\\n⚠️ IMPORTANT REMINDERS:\")\n",
    "print(\"   • Always backup before applying changes\")\n",
    "print(\"   • Test on a small collection first\")\n",
    "print(\"   • Apply deletions BEFORE additions\")\n",
    "print(\"   • Validate results thoroughly\")\n",
    "\n",
    "if config.OUTPUT_DIR:\n",
    "    print(f\"\\n📁 Your files are ready in: {config.OUTPUT_DIR}/\")\n",
    "    print(f\"   🕐 Generated at: {config.TIMESTAMP}\")\n",
    "    print(f\"   🎛️ Using cascade preset: {config.CASCADE_PRESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've successfully analyzed your OCL collection references and generated modernization files (if needed)!\n",
    "\n",
    "### 📁 Generated Files:\n",
    "- **`unversioned_references_*.json`** - Import this to add modernized references (if versioned refs found)\n",
    "- **`references_to_delete_*.json`** - Import this FIRST to remove old versioned references (if any)  \n",
    "- **`migration_report_*.txt`** - Detailed report with statistics and instructions\n",
    "\n",
    "### ✨ Key Improvements in This Version:\n",
    "- **🎯 Smart Processing**: Only modernizes versioned references, leaves unversioned ones unchanged\n",
    "- **🚫 Duplicate Prevention**: Detects and optionally skips duplicate expressions\n",
    "- **🎛️ Cascade Presets**: Support for OpenMRS and custom cascade configurations\n",
    "- **📊 Better Reporting**: More detailed statistics and validation\n",
    "\n",
    "### 🔗 Useful Links:\n",
    "- **GitHub Issue**: [#2212](https://github.com/OpenConceptLab/ocl_issues/issues/2212)\n",
    "- **OCL Bulk Import Docs**: [OCL API Reference](https://docs.openconceptlab.org/en/latest/oclapi/apireference/bulkimporting.html)\n",
    "- **Cascade Documentation**: [OCL Cascade Reference](https://docs.openconceptlab.org/en/latest/oclapi/apireference/cascade.html)\n",
    "\n",
    "### ⚠️ Remember:\n",
    "1. **Backup first** - Create a version of your collection before importing\n",
    "2. **Test first** - Try on a test collection before production\n",
    "3. **Order matters** - Import deletions before additions\n",
    "4. **Validate** - Check your collection expansion after migration\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook implements the enhanced OCL Reference Modernizer as specified in GitHub issue #2212, with improved behavior for processing only versioned references, preventing duplicates, and supporting cascade presets.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
